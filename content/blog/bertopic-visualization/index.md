---
title: Interpreting BERTopic neural topic modeling results
date: "2024-03-25T22:12:03.284Z"
description: "Visualizing BERTopic: interpretable topics and understanding their representation, how it works and where it works."
---

In the last few months, I have studied topic modeling neural networks and their applications. I have been developing a strategy to represent the topics from a database of complaints about companies in Portuguese. One of the tests that I have been conducting is to use the BERTopic approach along with the embeddings from BERTimbau (a language model trained in Portuguese, based on the BERT transformer model).

But what I want to explore here are the initial results and their visualization. I have trained the model with a few documents (10,000 to be exact) and will generate some visualizations for these examples. This step is crucial to understand the model, how it works, and where it works. We can look at the generated topics and see what makes sense and what does not in our strategy.


## Visualize Topics

This is the Intertopic Distance Map, which displays the topics generated in a 2D representation. Each point represents a topic, and the distance between points indicates the similarity or dissimilarity between topics.

We can also analyze that the use of the default hyperparameters of the BERTopic approach generates some clusters of topics, and in some cases, a topic contains a great number of other "sub-topics."

But, most importantly, let's discuss how this plot is generated. In BERTopic, the final representation of the topics is generated using c-TF-IDF, a measure for representing the importance of a term to a topic. This is done after document embedding, clustering, and dimensionality reduction.

So at this point, we model the importance of words in clusters of documents (topics). We generate topic-word distributions for each cluster of documents.

To build this visualization, the c-TF-IDF representation of the topics is embedded using UMAP. We apply UMAP to reduce the high-dimensional c-TF-IDF representation of the topics to the 2D representation we can see in the image. UMAP preserves local and global structure in the data.

<iframe src="/distance_map.html" width="600" height="400"></iframe>

The representation shows in a 2D space the relation between each topic generated by the model. Curiously, we can see not just the clustering of documents, but also the clustering of topics within topics.

The vectorial distance between each topic represents their similarity. It's interesting to note, for example, that there is a cluster of smartphone topics, energy consumption topics, travel agency topics, and bank topics. Also, the distance between smartphone topics and TV cable plans is smaller than with travel agencies.

Then, we can visualize the results of the topic modeling and validate the outcome. 

## Visualize Topic Hierarchy

BERTopic topic modeling strategy creates several topics that can be clustered together; they represent aspects that are semantically and syntactically similar. We could observe in the last visualization the relationship between each topic (indicated by the proximity).

We can also observe this relationship through the topic hierarchy, the created topics can be hierarchically organized. We can expand this visualization to create topic clusters and visualize how they relate to one another.

The next step is to observe what happens to the topic representations when merging topics. Merging topics is an important step in this process because it allows us to determine the best representation of topics that are different and encompass a vast number of subjects, without being repetitive and non-representative.

<iframe src="/hierarchical_labels.html" width="600" height="400"></iframe>

The black circles depict topics at the hierarchy level. This enables us to observe the consequences of merging topics and their outcomes, including the name and the top 10 words representing each topic. The merging process can vary in its logic depending on the topic, and now we can visualize that. Additionally, we can discern sub-topics within broader themes, providing us with a deeper comprehension of the topic hierarchy.

There are additional visualization methods available for understanding what's happening within BERTopic, particularly if we want to observe the process at a document level, their embedding, and categorization. But for now, these two visualizations are crucial for distinguishing topic generation and validating the functionality of our approach. While there are still adjustments I plan to make in the BERTopic base algorithm, I am sure that these visualizations will be used in every model analysis.
